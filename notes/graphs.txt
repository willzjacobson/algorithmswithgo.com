Representations of graphs:
G = (V,E), where V is the set of vertices and E is the set of edges
1) adjacency list
  - This is the most common choice.
  - Provides a compact way to represent sparse graphs - those for which E is much less than V^2.
  - Consists of an array "Adj" of lists, one for each vertex in V. Each list u contains all the vertices v such that there is an edge (u,v) in E. That is, Adj[u] consists of all the vertices adjacent to u in G (or pointers to those vertices).
  - For a directed graph, the sum of the lengths of all the adjacency lists is E. For undirected graphs it is 2E (since edges can be said to go both ways). 
  - Requires O(V+E) memory for both directed and undirected graphs. 
  - Weighted graphs can be handled by storing the weight w(u,v) of the edge (u,v) with vertex v in u's adjacency list.
  - potential disadvantage: no quicker way to search for a particular edge (u,v) than to search for v in the adjacency list Adj[u]. An adjacency matrix (see below) remedies this at the cost of more memory.
2) adjacency matrix
  - Useful when the graph is dense - that is, E is close to V^2
  - Also useful is we need to tell quickly if there is an edge connexting 2 given vertices (for example, in 2 of the all-pairs-shortest-paths algorithms assume their input graphs are represented by adjacency matrices).
  - We assume all the vertices are numbered. Then, the matric representation of a graph consist of a V*V matrix A. An entry Aij is 1 if an edge exists between i and j.
  - Requires O(V^2) memory.
  - For an undirected graph, the adjacency matrix is its own transpose, since (u,v) and (v,u) represent the same edge. For this reason, we sometimes only store the entries on and above the diagonal to save memory.
  - To represent a weighted graph, can just store the weight value rather than 1.
  - Though more memory is required for an adjacency matrix than in an adjacency list, they are simpler, and require only 1 bit per entry (unless you're storing the weight rather than just yes/no).

-=- Breadth-first search
The archetype for many important graph algorithms. Prim's minimum-spanning-tree algo and Dijkstra's single-source shortest-path algo use similar ideas.
Starting with a source vertex s, breadth-first search discovers all vertices at distance k from s before discovering vertices at distance k+1.
BFS uses node colors and a Queue as a tool to keep track of traversal. 
  - At the start, all nodes are white except the "source" vertex, which is gray.
  - For each vertex connected to s, we:
    - turn it gray because it is now "discovered". 
    - Set its "parent" attribute to vertex s.
    - Set it's "distance" attribute to be 1 + that of its parent's (its distance from s)
    - Enqueue it so it is later processed just like s is being processed now. 
  - We then turn s from gray to black, having fully processed it.
  - While the queue has length, we continually pop off vertices and process them as above.
By adding the "parent" attribute to each vertex connected to s, the BFS algorithm produces a subgraph that we call a "breadth-first tree" (it is in fact a tree, since |Eπ| = |Vπ| - 1), which is itself a graph denoted by Gπ = (Vπ, Eπ) that contains all vertices reachable from s. 
The breadth-first tree records a shortest path between each vertex and s.
Runtime:
Each vertex is handled by the queue once, and when it is, we handle each one of its edges. Thus, the runtime of BFS is O(V+E), That is, it's linear with respect to the adjacency list-representation. 

-=- Depth-first search
DFS is often used as a subroutine in another algorithm (as we shall see later).
Works on directed and undirected graphs.
Search "deeper" in the graph whenever possible:
  - Explores edges out of the most recently discovered vertex v that still has unexplored edges leaving it. 
  - Whenever a vertex v is discovered, we set v.P to the vertex from which is is discovered (as in BFS).
  - Once all of v's edges are explored, the seaerch "backtracks" to explore edges from the vertex from which v discovered. 
  - This continues until we have reached all vertices reachable from the original source vertex. 
  - If any undiscovered vertices remain, we repeat the process for them until every vertex has been discovered.
  - Like BFS, we use the colors to keep track of where we've been, so each node only gets added to 1 tree.
  - Each vertex also gets 2 timestamps (time is kept globally by an incrementing integer): one marking the time when v is discovered (grayed), and once when it is finished (blackened). Timestamps are between 1 and 2V, since each vertex is stamped twice.
Unlike BFS, the predecessor graph generated by DFS may consist of several trees, since the search may repeat from ultiple sources. We define this predecessor graph as:
  Gπ = (V, Eπ), where 
  Gπ is a "depth-first forest" comprised of several "depth-first trees", and
  the edges in Eπ are the tree edges.
The exact graph resulting from running DFS will vary based on the order of the nodes processed, and the order of edges recorded in the adjacency-list. This generally does not matter.
Runtime:
We call the helper DFSVisit once on each vertex (O(V)), and the function loops through all the vertices adjacent to that vertex, only calling itself again for vertices that are still white (O(E)). Thus, runtime for DFS, like BFS, is O(V+E).

Properties of DFS
- The structure of the trees in the resulting forest exactly mirrors the structure of the recursive calls of DFSVisit.
- Theorem: The processing of nodes form a parenthetical structure. That is, for any 2 vertices u and v, exactly 1 of the following conditions is true:
  1. The intervals [u.start, u.end] and [v.start, v.end] are disjoint, and neither u nor v is a descendant of the other in the depth-first forest.
  2. [u.start, u.end] is entirely contained within [v.start, v.end], and u is a descendant of v in a depth-first tree.
  3. [v.start, v.end] is entirely contained within [u.start, u.end], and v is a descendant of u in a depth-first tree.
- Theorem: vertex v is a proper descendant of vertex u in the depth-first forest for a (directed or undirected) graph if and only if u.start < v.start < v.end < u.end.
- "White path theorem": In a depth-first forest of a (directed or undirected) graph, vertex v is a descendent of vertex u if and only if at the time u.start, there is a path connecting u to v consisting of only white vertices.

Classification of edges
DFS can be used to classify edges of an input graph, and the type of edge can provide info about the graph. For example, we can tell that a directed graph is acyclic if and only if a depth-first search yields no "back" edges (since that would mean the descendant has a path to the ancestor that is different form the path DFS has already taken from the ancestor to the descendant).
4 types of edges:
  1) "Tree edges" are edges in the depth-first forest Gπ. Edge (u,v) is a tree edge if v was first discovered by exploring edge (u,v). (going down)
  2) "Back edges" are those edges (u,v) connected u to an ancestor v in a depth-first tree. This includes self-loops, which may occur in directed graphs. (ran out of white vertices, going back up)
  3) "Forward edges" are those nontree edges (u,v) connecting a vertex u to a descendent v in a depth-first tree. (not a tree edge, since the descendent is no longer white)
  4) "Cross edges" are all other edges. They can go between vertices in the same DF tree, as long as one vertex is not an ancestor of the other, or they can go between vertices in different DF trees.
During DFS, when we explore the edge (u,v), the color of v tells us something about the edge:
 - White indicates a tree edge
 - Gray indicates a back edge
 - Black indicates a forward or cross edge. The edge (u,v) is a forward edge if u.start < v.start, and a cross edge if u.start > v.start.
An undirected graph has ambiguity as to the type of each edge, since each edge occurs twice. Don't worry about it - whichever you encounter first.
Theorem: In a DFS of an undirected graph, every edge is either a tree edge or a back edge.

Topological sorting of a directed ascyclic graph (dag) using DFS
Topological sorting is a linear ordering of vertices such that for every directed edge (u,v), u comes before v in the odering. 
Topological sorting of a graph is not possible if the graph is not a dag.

-=- Strongly Connected Components
A classic application of DFS is decomposing a directed graph into its strongly connected components (SCCs). It is a common first step in many graph algos, and we can do it using 2 depth-first searches. .
A strongly connected component of a graph is a maximal set of vertices such that every pair of vertices are reachable from each other.
Our algo for finding the SCCs of a graph G uses the transpose of G, which we define as GT=(V, ET), where ET consists of the edges of G with their directions reversed. The time to compute GT from the adjacency-list representation of G is O(V+E).
Note that G and GT have the same SCCs: vertices u and v are reachable from each other in G if and only if they are reachable from each other in GT. 
The following linear time O(V+E) algorithm computes the SCCs of a directed graph G=(V,E) using 2 depth-first searches, one on G and one on GT:
STRONGLY-CONNECTED-COMPONENTS(G)
  1. call DFS(G) to compute finishing times u.f for each vertex u
  2. compute GT
  3. call DFS(GT), but in the main loop of DFS, consider the vertices in order of decreasing u.f as computed in line 1 (that is, in topologically sorted order)
  4. output the vertices of each tree in the depth-first forest formed in step 3 as a separate SCC
The key property is that the component graph is a dag (if it was not, then we would not have distinct SCCs).

- Theorem: Let C and C' be distinct SSCs in a directed graph G=(V,E). Suppose there is an edge (u,v) in E, where u is in C and v is in C'. Then, f(C) > f(C'). That is, the max finishing time in the tree C is greater than that of C'. This is true regardless of whether any vertex in C is dicsovered by DFS before any vertex in C', or vice versa.
- Corrollary: The above theorem tells us that each edge in GT that goes between distinct SSCs, goes from a component with an earlier finishing time in the DFS to a component with later finishing time. That is, if there in an edge (u,v) in ET, where u in C and v in C', then f(C) < F(C').
- The above corrollary tells us why the SCC algo works: 
  - When we perform the 2nd DFS (on GT) in step 3, we start with the SCC whose finishing time is the maximum in the set of SCCs. The search starts from some vertex in C, and visits all other vertices in C. The above corrollary tells us that if C contains no vertices that point to other SCCs. Thus, the resulting depth-first tree rooted at x contains the vertices in C and no others. 
  - The next white node y that the DFS in step 3 then finds is a member of the SCC C' with the second greatest finish time. Vertices in C' only contain edges pointing to other vertices in C', and to C (but all vertices in C are no longer white). Thus, the resulting depth-first tree rooted at y contains the vertices in C' and no others. And so on for each SCC. 
  - Therefore, the SSC algo computes the SCCs in G.

